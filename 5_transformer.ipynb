{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23802a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.functional import cross_entropy,softmax, relu\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import utils\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a15347",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ef0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, n_head, model_dim, drop_rate):\n",
    "        super().__init__()\n",
    "        self.head_dim = model_dim // n_head\n",
    "        self.n_head = n_head\n",
    "        self.model_dim = model_dim\n",
    "        self.wq = nn.Linear(model_dim, n_head * self.head_dim)\n",
    "        self.wk = nn.Linear(model_dim, n_head * self.head_dim)\n",
    "        self.wv = nn.Linear(model_dim, n_head * self.head_dim)\n",
    "\n",
    "        self.o_dense = nn.Linear(model_dim, model_dim)\n",
    "        self.o_drop = nn.Dropout(drop_rate)\n",
    "        self.layer_norm = nn.LayerNorm(model_dim)\n",
    "        self.attention = None\n",
    "\n",
    "    def forward(self,q,k,v,mask,training):\n",
    "        # residual connect\n",
    "        residual = q\n",
    "        dim_per_head= self.head_dim\n",
    "        num_heads = self.n_head\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        # linear projection\n",
    "        key = self.wk(k)    # [n, step, num_heads * head_dim]\n",
    "        value = self.wv(v)  # [n, step, num_heads * head_dim]\n",
    "        query = self.wq(q)  # [n, step, num_heads * head_dim]\n",
    "\n",
    "        # split by head\n",
    "        query = self.split_heads(query)       # [n, n_head, q_step, h_dim]\n",
    "        key = self.split_heads(key)\n",
    "        value = self.split_heads(value)  # [n, h, step, h_dim]\n",
    "        context = self.scaled_dot_product_attention(query,key, value, mask)    # [n, q_step, h*dv]\n",
    "        o = self.o_dense(context)   # [n, step, dim]\n",
    "        o = self.o_drop(o)\n",
    "\n",
    "        o = self.layer_norm(residual+o)\n",
    "        return o\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        x = torch.reshape(x,(x.shape[0], x.shape[1], self.n_head, self.head_dim))\n",
    "        return x.permute(0,2,1,3)\n",
    "    \n",
    "    def scaled_dot_product_attention(self, q, k, v, mask=None):\n",
    "        dk = torch.tensor(k.shape[-1]).type(torch.float)\n",
    "        score = torch.matmul(q,k.permute(0,1,3,2)) / (torch.sqrt(dk) + 1e-8)    # [n, n_head, step, step]\n",
    "        if mask is not None:\n",
    "            # change the value at masked position to negative infinity,\n",
    "            # so the attention score at these positions after softmax will close to 0.\n",
    "            score = score.masked_fill_(mask,-np.inf)\n",
    "        self.attention = softmax(score,dim=-1)\n",
    "        context = torch.matmul(self.attention,v)    # [n, num_head, step, head_dim]\n",
    "        context = context.permute(0,2,1,3)          # [n, step, num_head, head_dim]\n",
    "        context = context.reshape((context.shape[0], context.shape[1],-1))  \n",
    "        return context  # [n, step, model_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f45b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self,model_dim, dropout = 0.0):\n",
    "        super().__init__()\n",
    "        dff = model_dim*4\n",
    "        self.l = nn.Linear(model_dim,dff)\n",
    "        self.o = nn.Linear(dff,model_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(model_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        o = relu(self.l(x))\n",
    "        o = self.o(o)\n",
    "        o = self.dropout(o)\n",
    "\n",
    "        o = self.layer_norm(x + o)\n",
    "        return o    # [n, step, dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8867f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, n_head, emb_dim, drop_rate):\n",
    "        super().__init__()\n",
    "        self.mh = MultiHead(n_head, emb_dim, drop_rate)\n",
    "        self.ffn = PositionWiseFFN(emb_dim,drop_rate)\n",
    "    \n",
    "    def forward(self, xz, training, mask):\n",
    "        # xz: [n, step, emb_dim]\n",
    "        context = self.mh(xz, xz, xz, mask, training)  # [n, step, emb_dim]\n",
    "        o = self.ffn(context)\n",
    "        return o\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_head, emb_dim, drop_rate, n_layer):\n",
    "        super().__init__()\n",
    "        self.encoder_layers = nn.ModuleList(\n",
    "            [EncoderLayer(n_head, emb_dim, drop_rate) for _ in range(n_layer)]\n",
    "        )    \n",
    "    def forward(self, xz, training, mask):\n",
    "\n",
    "        for encoder in self.encoder_layers:\n",
    "            xz = encoder(xz,training,mask)\n",
    "        return xz       # [n, step, emb_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d48a5826",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,n_head,model_dim,drop_rate):\n",
    "        super().__init__()\n",
    "        self.mh = nn.ModuleList([MultiHead(n_head, model_dim, drop_rate) for _ in range(2)])\n",
    "        self.ffn = PositionWiseFFN(model_dim,drop_rate)\n",
    "    \n",
    "    def forward(self,yz, xz, training, yz_look_ahead_mask,xz_pad_mask):\n",
    "        dec_output = self.mh[0](yz, yz, yz, yz_look_ahead_mask, training)   # [n, step, model_dim]\n",
    "        \n",
    "        dec_output = self.mh[1](dec_output, xz, xz, xz_pad_mask, training)  # [n, step, model_dim]\n",
    "\n",
    "        dec_output = self.ffn(dec_output)   # [n, step, model_dim]\n",
    "\n",
    "        return dec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fdc8109",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_head, model_dim, drop_rate, n_layer):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = n_layer\n",
    "\n",
    "        self.decoder_layers = nn.ModuleList(\n",
    "            [DecoderLayer(n_head, model_dim, drop_rate) for _ in range(n_layer)]\n",
    "        )\n",
    "    \n",
    "    def forward(self, yz, xz, training, yz_look_ahead_mask, xz_pad_mask):\n",
    "        for decoder in self.decoder_layers:\n",
    "            yz = decoder(yz, xz, training, yz_look_ahead_mask, xz_pad_mask)\n",
    "        return yz   # [n, step, model_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a20e094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(nn.Module):\n",
    "    def __init__(self, max_len, emb_dim, n_vocab):\n",
    "        super().__init__()\n",
    "        pos = np.expand_dims(np.arange(max_len),1)  # [max_len, 1]\n",
    "        pe = pos / np.power(1000, 2*np.expand_dims(np.arange(emb_dim)//2,0)/emb_dim)  # [max_len, emb_dim]\n",
    "        pe[:, 0::2] = np.sin(pe[:, 0::2])\n",
    "        pe[:, 1::2] = np.cos(pe[:, 1::2])\n",
    "        pe = np.expand_dims(pe,0) # [1, max_len, emb_dim]\n",
    "        self.pe = torch.from_numpy(pe).type(torch.float32)\n",
    "        self.embeddings = nn.Embedding(n_vocab,emb_dim)\n",
    "        self.embeddings.weight.data.normal_(0,0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        device = self.embeddings.weight.device\n",
    "        self.pe = self.pe.to(device)    \n",
    "        x_embed = self.embeddings(x) + self.pe  # [n, step, emb_dim]\n",
    "        return x_embed  # [n, step, emb_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22cd4c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, n_vocab, max_len, n_layer = 6, emb_dim=512, n_head = 8, drop_rate=0.1, padding_idx=0):\n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "        self.padding_idx = torch.tensor(padding_idx)\n",
    "        self.dec_v_emb = n_vocab \n",
    "\n",
    "        self.embed = PositionEmbedding(max_len, emb_dim, n_vocab)\n",
    "        self.encoder = Encoder(n_head, emb_dim, drop_rate, n_layer)\n",
    "        self.decoder = Decoder(n_head, emb_dim, drop_rate, n_layer)\n",
    "        self.o = nn.Linear(emb_dim,n_vocab)\n",
    "        self.opt = torch.optim.Adam(self.parameters(),lr=0.002)\n",
    "    \n",
    "    def forward(self,x,y,training= None):\n",
    "        x_embed, y_embed = self.embed(x), self.embed(y) # [n, step, emb_dim] * 2\n",
    "        pad_mask = self._pad_mask(x)    # [n, 1, step, step]\n",
    "        encoded_z = self.encoder(x_embed,training,pad_mask) # [n, step, emb_dim]\n",
    "        yz_look_ahead_mask = self._look_ahead_mask(y)   # [n, 1, step, step]\n",
    "        decoded_z = self.decoder(y_embed,encoded_z, training, yz_look_ahead_mask, pad_mask) # [n, step, emb_dim]\n",
    "        o = self.o(decoded_z)   # [n, step, n_vocab]\n",
    "        return o\n",
    "    \n",
    "    def step(self, x, y):\n",
    "        self.opt.zero_grad()\n",
    "        logits = self(x,y[:, :-1],training=True)\n",
    "        pad_mask = ~torch.eq(y[:,1:],self.padding_idx)  # [n, seq_len]\n",
    "        loss = cross_entropy(logits.reshape(-1, self.dec_v_emb),y[:,1:].reshape(-1))\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "        return loss.cpu().data.numpy(), logits\n",
    "\n",
    "    def _pad_bool(self, seqs):\n",
    "        o = torch.eq(seqs,self.padding_idx) # [n, step]\n",
    "        return o\n",
    "    def _pad_mask(self, seqs):\n",
    "        len_q = seqs.size(1)\n",
    "        mask = self._pad_bool(seqs).unsqueeze(1).expand(-1,len_q,-1)    # [n, len_q, step]\n",
    "        return mask.unsqueeze(1)    # [n, 1, len_q, step]\n",
    "    \n",
    "    def _look_ahead_mask(self,seqs):\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size, seq_len = seqs.shape\n",
    "        mask = torch.triu(torch.ones((seq_len,seq_len), dtype=torch.long), diagonal=1).to(device)  # [seq_len ,seq_len]\n",
    "        mask = torch.where(self._pad_bool(seqs)[:,None,None,:],1,mask[None,None,:,:]).to(device)   # [n, 1, seq_len, seq_len]\n",
    "        return mask>0   # [n, 1, seq_len, seq_len]\n",
    "    \n",
    "    def translate(self, src, v2i, i2v):\n",
    "        self.eval()\n",
    "        device = next(self.parameters()).device\n",
    "        src_pad = src\n",
    "        # Initialize Decoder input by constructing a matrix M([n, self.max_len+1]) with initial value:\n",
    "        # M[n,0] = start token id\n",
    "        # M[n,:] = 0\n",
    "        target = torch.from_numpy(utils.pad_zero(np.array([[v2i[\"<GO>\"], ] for _ in range(len(src))]), self.max_len+1)).to(device)\n",
    "        x_embed = self.embed(src_pad)\n",
    "        encoded_z = self.encoder(x_embed,False,mask=self._pad_mask(src_pad))\n",
    "        for i in range(0,self.max_len):\n",
    "            y = target[:,:-1]\n",
    "            y_embed = self.embed(y)\n",
    "            decoded_z = self.decoder(y_embed,encoded_z,False,self._look_ahead_mask(y),self._pad_mask(src_pad))\n",
    "            o = self.o(decoded_z)[:,i,:]\n",
    "            idx = o.argmax(dim = 1).detach()\n",
    "            # Update the Decoder input, to predict for the next position.\n",
    "            target[:,i+1] = idx\n",
    "        self.train()\n",
    "        return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba63aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(emb_dim=32,n_layer=3,n_head=4):\n",
    "    \n",
    "    dataset = utils.DateData(4000)\n",
    "    print(\"Chinese time order: yy/mm/dd \",dataset.date_cn[:3],\"\\nEnglish time order: dd/M/yyyy\", dataset.date_en[:3])\n",
    "    print(\"Vocabularies: \", dataset.vocab)\n",
    "    print(f\"x index sample:  \\n{dataset.idx2str(dataset.x[0])}\\n{dataset.x[0]}\",\n",
    "    f\"\\ny index sample:  \\n{dataset.idx2str(dataset.y[0])}\\n{dataset.y[0]}\")\n",
    "    loader = DataLoader(dataset,batch_size=32,shuffle=True)\n",
    "    model = Transformer(n_vocab=dataset.num_word, max_len=MAX_LEN, n_layer = n_layer, emb_dim=emb_dim, n_head = n_head, drop_rate=0.1, padding_idx=0)\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU train avaliable\")\n",
    "        device =torch.device(\"cuda\")\n",
    "        model = model.cuda()\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        model = model.cpu()\n",
    "    for i in range(100):\n",
    "        for batch_idx , batch in enumerate(loader):\n",
    "            bx, by, decoder_len = batch\n",
    "            bx, by = torch.from_numpy(utils.pad_zero(bx,max_len = MAX_LEN)).type(torch.LongTensor).to(device), torch.from_numpy(utils.pad_zero(by,MAX_LEN+1)).type(torch.LongTensor).to(device)\n",
    "            loss, logits = model.step(bx,by)\n",
    "            if batch_idx%50 == 0:\n",
    "                target = dataset.idx2str(by[0, 1:-1].cpu().data.numpy())\n",
    "                pred = model.translate(bx[0:1],dataset.v2i,dataset.i2v)\n",
    "                res = dataset.idx2str(pred[0].cpu().data.numpy())\n",
    "                src = dataset.idx2str(bx[0].cpu().data.numpy())\n",
    "                print(\n",
    "                    \"Epoch: \",i,\n",
    "                    \"| t: \", batch_idx,\n",
    "                    \"| loss: %.3f\" % loss,\n",
    "                    \"| input: \", src,\n",
    "                    \"| target: \", target,\n",
    "                    \"| inference: \", res,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a606e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese time order: yy/mm/dd  ['31-04-25', '04-07-17', '33-06-06'] \n",
      "English time order: dd/M/yyyy ['25/Apr/2031', '17/Jul/2004', '06/Jun/2033']\n",
      "Vocabularies:  {'4', '6', '/', 'Oct', '2', '7', 'Jan', 'Mar', '9', '5', '<GO>', 'Jun', 'Aug', '0', 'Apr', 'Dec', '3', 'Jul', '1', '<PAD>', '8', 'May', 'Feb', '-', 'Sep', '<EOS>', 'Nov'}\n",
      "x index sample:  \n",
      "31-04-25\n",
      "[6 4 1 3 7 1 5 8] \n",
      "y index sample:  \n",
      "<GO>25/Apr/2031<EOS>\n",
      "[14  5  8  2 15  2  5  3  6  4 13]\n",
      "GPU train avaliable\n",
      "Epoch:  0 | t:  0 | loss: 3.490 | input:  88-12-12<PAD><PAD><PAD> | target:  12/Dec/1988<EOS> | inference:  <GO>///////////\n",
      "Epoch:  0 | t:  50 | loss: 1.192 | input:  86-05-18<PAD><PAD><PAD> | target:  18/May/1986<EOS> | inference:  <GO>20/Aug/2020<EOS>\n",
      "Epoch:  0 | t:  100 | loss: 0.827 | input:  82-03-14<PAD><PAD><PAD> | target:  14/Mar/1982<EOS> | inference:  <GO>18/Jan/2028<EOS>\n",
      "Epoch:  1 | t:  0 | loss: 0.465 | input:  86-02-22<PAD><PAD><PAD> | target:  22/Feb/1986<EOS> | inference:  <GO>22/Dec/1986<EOS>\n",
      "Epoch:  1 | t:  50 | loss: 0.255 | input:  79-01-06<PAD><PAD><PAD> | target:  06/Jan/1979<EOS> | inference:  <GO>06/Mar/1979<EOS>\n",
      "Epoch:  1 | t:  100 | loss: 0.232 | input:  06-05-25<PAD><PAD><PAD> | target:  25/May/2006<EOS> | inference:  <GO>25/Jul/2006<EOS>\n",
      "Epoch:  2 | t:  0 | loss: 0.171 | input:  26-05-08<PAD><PAD><PAD> | target:  08/May/2026<EOS> | inference:  <GO>08/May/2026<EOS>\n",
      "Epoch:  2 | t:  50 | loss: 0.034 | input:  96-06-16<PAD><PAD><PAD> | target:  16/Jun/1996<EOS> | inference:  <GO>16/Jun/1996<EOS>\n",
      "Epoch:  2 | t:  100 | loss: 0.013 | input:  19-07-30<PAD><PAD><PAD> | target:  30/Jul/2019<EOS> | inference:  <GO>30/Jul/2019<EOS>\n",
      "Epoch:  3 | t:  0 | loss: 0.010 | input:  90-04-02<PAD><PAD><PAD> | target:  02/Apr/1990<EOS> | inference:  <GO>02/Apr/1990<EOS>\n",
      "Epoch:  3 | t:  50 | loss: 0.007 | input:  79-01-17<PAD><PAD><PAD> | target:  17/Jan/1979<EOS> | inference:  <GO>17/Jan/1979<EOS>\n",
      "Epoch:  3 | t:  100 | loss: 0.004 | input:  97-12-26<PAD><PAD><PAD> | target:  26/Dec/1997<EOS> | inference:  <GO>26/Dec/1997<EOS>\n",
      "Epoch:  4 | t:  0 | loss: 0.004 | input:  92-01-18<PAD><PAD><PAD> | target:  18/Jan/1992<EOS> | inference:  <GO>18/Jan/1992<EOS>\n",
      "Epoch:  4 | t:  50 | loss: 0.003 | input:  08-11-13<PAD><PAD><PAD> | target:  13/Nov/2008<EOS> | inference:  <GO>13/Nov/2008<EOS>\n",
      "Epoch:  4 | t:  100 | loss: 0.003 | input:  13-05-03<PAD><PAD><PAD> | target:  03/May/2013<EOS> | inference:  <GO>03/May/2013<EOS>\n",
      "Epoch:  5 | t:  0 | loss: 0.003 | input:  31-11-06<PAD><PAD><PAD> | target:  06/Nov/2031<EOS> | inference:  <GO>06/Nov/2031<EOS>\n",
      "Epoch:  5 | t:  50 | loss: 0.002 | input:  85-11-28<PAD><PAD><PAD> | target:  28/Nov/1985<EOS> | inference:  <GO>28/Nov/1985<EOS>\n",
      "Epoch:  5 | t:  100 | loss: 0.002 | input:  04-02-14<PAD><PAD><PAD> | target:  14/Feb/2004<EOS> | inference:  <GO>14/Feb/2004<EOS>\n",
      "Epoch:  6 | t:  0 | loss: 0.002 | input:  07-01-13<PAD><PAD><PAD> | target:  13/Jan/2007<EOS> | inference:  <GO>13/Jan/2007<EOS>\n",
      "Epoch:  6 | t:  50 | loss: 0.001 | input:  78-03-15<PAD><PAD><PAD> | target:  15/Mar/1978<EOS> | inference:  <GO>15/Mar/1978<EOS>\n",
      "Epoch:  6 | t:  100 | loss: 0.001 | input:  08-07-25<PAD><PAD><PAD> | target:  25/Jul/2008<EOS> | inference:  <GO>25/Jul/2008<EOS>\n",
      "Epoch:  7 | t:  0 | loss: 0.001 | input:  99-01-30<PAD><PAD><PAD> | target:  30/Jan/1999<EOS> | inference:  <GO>30/Jan/1999<EOS>\n",
      "Epoch:  7 | t:  50 | loss: 0.001 | input:  95-07-25<PAD><PAD><PAD> | target:  25/Jul/1995<EOS> | inference:  <GO>25/Jul/1995<EOS>\n",
      "Epoch:  7 | t:  100 | loss: 0.001 | input:  94-05-08<PAD><PAD><PAD> | target:  08/May/1994<EOS> | inference:  <GO>08/May/1994<EOS>\n",
      "Epoch:  8 | t:  0 | loss: 0.001 | input:  77-08-06<PAD><PAD><PAD> | target:  06/Aug/1977<EOS> | inference:  <GO>06/Aug/1977<EOS>\n",
      "Epoch:  8 | t:  50 | loss: 0.001 | input:  31-11-29<PAD><PAD><PAD> | target:  29/Nov/2031<EOS> | inference:  <GO>29/Nov/2031<EOS>\n",
      "Epoch:  8 | t:  100 | loss: 0.001 | input:  24-04-09<PAD><PAD><PAD> | target:  09/Apr/2024<EOS> | inference:  <GO>09/Apr/2024<EOS>\n",
      "Epoch:  9 | t:  0 | loss: 0.001 | input:  08-05-19<PAD><PAD><PAD> | target:  19/May/2008<EOS> | inference:  <GO>19/May/2008<EOS>\n",
      "Epoch:  9 | t:  50 | loss: 0.001 | input:  93-06-14<PAD><PAD><PAD> | target:  14/Jun/1993<EOS> | inference:  <GO>14/Jun/1993<EOS>\n",
      "Epoch:  9 | t:  100 | loss: 0.001 | input:  34-09-17<PAD><PAD><PAD> | target:  17/Sep/2034<EOS> | inference:  <GO>17/Sep/2034<EOS>\n",
      "Epoch:  10 | t:  0 | loss: 0.001 | input:  76-04-07<PAD><PAD><PAD> | target:  07/Apr/1976<EOS> | inference:  <GO>07/Apr/1976<EOS>\n",
      "Epoch:  10 | t:  50 | loss: 0.001 | input:  77-01-17<PAD><PAD><PAD> | target:  17/Jan/1977<EOS> | inference:  <GO>17/Jan/1977<EOS>\n",
      "Epoch:  10 | t:  100 | loss: 0.001 | input:  93-07-25<PAD><PAD><PAD> | target:  25/Jul/1993<EOS> | inference:  <GO>25/Jul/1993<EOS>\n",
      "Epoch:  11 | t:  0 | loss: 0.000 | input:  99-04-10<PAD><PAD><PAD> | target:  10/Apr/1999<EOS> | inference:  <GO>10/Apr/1999<EOS>\n",
      "Epoch:  11 | t:  50 | loss: 0.000 | input:  84-01-02<PAD><PAD><PAD> | target:  02/Jan/1984<EOS> | inference:  <GO>02/Jan/1984<EOS>\n",
      "Epoch:  11 | t:  100 | loss: 0.000 | input:  31-09-02<PAD><PAD><PAD> | target:  02/Sep/2031<EOS> | inference:  <GO>02/Sep/2031<EOS>\n",
      "Epoch:  12 | t:  0 | loss: 0.000 | input:  85-01-28<PAD><PAD><PAD> | target:  28/Jan/1985<EOS> | inference:  <GO>28/Jan/1985<EOS>\n",
      "Epoch:  12 | t:  50 | loss: 0.000 | input:  83-02-03<PAD><PAD><PAD> | target:  03/Feb/1983<EOS> | inference:  <GO>03/Feb/1983<EOS>\n",
      "Epoch:  12 | t:  100 | loss: 0.000 | input:  15-03-08<PAD><PAD><PAD> | target:  08/Mar/2015<EOS> | inference:  <GO>08/Mar/2015<EOS>\n",
      "Epoch:  13 | t:  0 | loss: 0.000 | input:  84-04-17<PAD><PAD><PAD> | target:  17/Apr/1984<EOS> | inference:  <GO>17/Apr/1984<EOS>\n",
      "Epoch:  13 | t:  50 | loss: 0.000 | input:  82-06-13<PAD><PAD><PAD> | target:  13/Jun/1982<EOS> | inference:  <GO>13/Jun/1982<EOS>\n",
      "Epoch:  13 | t:  100 | loss: 0.000 | input:  26-02-03<PAD><PAD><PAD> | target:  03/Feb/2026<EOS> | inference:  <GO>03/Feb/2026<EOS>\n",
      "Epoch:  14 | t:  0 | loss: 0.000 | input:  99-03-17<PAD><PAD><PAD> | target:  17/Mar/1999<EOS> | inference:  <GO>17/Mar/1999<EOS>\n",
      "Epoch:  14 | t:  50 | loss: 0.000 | input:  90-10-09<PAD><PAD><PAD> | target:  09/Oct/1990<EOS> | inference:  <GO>09/Oct/1990<EOS>\n",
      "Epoch:  14 | t:  100 | loss: 0.000 | input:  75-05-24<PAD><PAD><PAD> | target:  24/May/1975<EOS> | inference:  <GO>24/May/1975<EOS>\n",
      "Epoch:  15 | t:  0 | loss: 0.000 | input:  92-10-02<PAD><PAD><PAD> | target:  02/Oct/1992<EOS> | inference:  <GO>02/Oct/1992<EOS>\n",
      "Epoch:  15 | t:  50 | loss: 0.000 | input:  87-07-29<PAD><PAD><PAD> | target:  29/Jul/1987<EOS> | inference:  <GO>29/Jul/1987<EOS>\n",
      "Epoch:  15 | t:  100 | loss: 0.000 | input:  04-07-31<PAD><PAD><PAD> | target:  31/Jul/2004<EOS> | inference:  <GO>31/Jul/2004<EOS>\n",
      "Epoch:  16 | t:  0 | loss: 0.000 | input:  83-04-19<PAD><PAD><PAD> | target:  19/Apr/1983<EOS> | inference:  <GO>19/Apr/1983<EOS>\n",
      "Epoch:  16 | t:  50 | loss: 0.000 | input:  87-03-10<PAD><PAD><PAD> | target:  10/Mar/1987<EOS> | inference:  <GO>10/Mar/1987<EOS>\n",
      "Epoch:  16 | t:  100 | loss: 0.000 | input:  04-06-25<PAD><PAD><PAD> | target:  25/Jun/2004<EOS> | inference:  <GO>25/Jun/2004<EOS>\n",
      "Epoch:  17 | t:  0 | loss: 0.000 | input:  19-04-01<PAD><PAD><PAD> | target:  01/Apr/2019<EOS> | inference:  <GO>01/Apr/2019<EOS>\n",
      "Epoch:  17 | t:  50 | loss: 0.000 | input:  00-04-10<PAD><PAD><PAD> | target:  10/Apr/2000<EOS> | inference:  <GO>10/Apr/2000<EOS>\n",
      "Epoch:  17 | t:  100 | loss: 0.000 | input:  81-12-23<PAD><PAD><PAD> | target:  23/Dec/1981<EOS> | inference:  <GO>23/Dec/1981<EOS>\n",
      "Epoch:  18 | t:  0 | loss: 0.000 | input:  06-08-12<PAD><PAD><PAD> | target:  12/Aug/2006<EOS> | inference:  <GO>12/Aug/2006<EOS>\n",
      "Epoch:  18 | t:  50 | loss: 0.000 | input:  89-05-13<PAD><PAD><PAD> | target:  13/May/1989<EOS> | inference:  <GO>13/May/1989<EOS>\n",
      "Epoch:  18 | t:  100 | loss: 0.000 | input:  30-12-05<PAD><PAD><PAD> | target:  05/Dec/2030<EOS> | inference:  <GO>05/Dec/2030<EOS>\n",
      "Epoch:  19 | t:  0 | loss: 0.000 | input:  91-10-03<PAD><PAD><PAD> | target:  03/Oct/1991<EOS> | inference:  <GO>03/Oct/1991<EOS>\n",
      "Epoch:  19 | t:  50 | loss: 0.000 | input:  23-01-02<PAD><PAD><PAD> | target:  02/Jan/2023<EOS> | inference:  <GO>02/Jan/2023<EOS>\n",
      "Epoch:  19 | t:  100 | loss: 0.000 | input:  90-06-10<PAD><PAD><PAD> | target:  10/Jun/1990<EOS> | inference:  <GO>10/Jun/1990<EOS>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20 | t:  0 | loss: 0.000 | input:  17-02-19<PAD><PAD><PAD> | target:  19/Feb/2017<EOS> | inference:  <GO>19/Feb/2017<EOS>\n",
      "Epoch:  20 | t:  50 | loss: 0.000 | input:  00-05-10<PAD><PAD><PAD> | target:  10/May/2000<EOS> | inference:  <GO>10/May/2000<EOS>\n",
      "Epoch:  20 | t:  100 | loss: 0.000 | input:  89-06-29<PAD><PAD><PAD> | target:  29/Jun/1989<EOS> | inference:  <GO>29/Jun/1989<EOS>\n",
      "Epoch:  21 | t:  0 | loss: 0.000 | input:  15-12-05<PAD><PAD><PAD> | target:  05/Dec/2015<EOS> | inference:  <GO>05/Dec/2015<EOS>\n",
      "Epoch:  21 | t:  50 | loss: 0.000 | input:  92-02-01<PAD><PAD><PAD> | target:  01/Feb/1992<EOS> | inference:  <GO>01/Feb/1992<EOS>\n",
      "Epoch:  21 | t:  100 | loss: 0.000 | input:  31-11-06<PAD><PAD><PAD> | target:  06/Nov/2031<EOS> | inference:  <GO>06/Nov/2031<EOS>\n",
      "Epoch:  22 | t:  0 | loss: 0.000 | input:  90-01-03<PAD><PAD><PAD> | target:  03/Jan/1990<EOS> | inference:  <GO>03/Jan/1990<EOS>\n",
      "Epoch:  22 | t:  50 | loss: 0.000 | input:  88-01-18<PAD><PAD><PAD> | target:  18/Jan/1988<EOS> | inference:  <GO>18/Jan/1988<EOS>\n",
      "Epoch:  22 | t:  100 | loss: 0.000 | input:  23-11-29<PAD><PAD><PAD> | target:  29/Nov/2023<EOS> | inference:  <GO>29/Nov/2023<EOS>\n",
      "Epoch:  23 | t:  0 | loss: 0.000 | input:  03-01-18<PAD><PAD><PAD> | target:  18/Jan/2003<EOS> | inference:  <GO>18/Jan/2003<EOS>\n",
      "Epoch:  23 | t:  50 | loss: 0.000 | input:  99-07-26<PAD><PAD><PAD> | target:  26/Jul/1999<EOS> | inference:  <GO>26/Jul/1999<EOS>\n",
      "Epoch:  23 | t:  100 | loss: 0.000 | input:  99-03-17<PAD><PAD><PAD> | target:  17/Mar/1999<EOS> | inference:  <GO>17/Mar/1999<EOS>\n",
      "Epoch:  24 | t:  0 | loss: 0.000 | input:  79-12-03<PAD><PAD><PAD> | target:  03/Dec/1979<EOS> | inference:  <GO>03/Dec/1979<EOS>\n",
      "Epoch:  24 | t:  50 | loss: 0.000 | input:  74-08-30<PAD><PAD><PAD> | target:  30/Aug/1974<EOS> | inference:  <GO>30/Aug/1974<EOS>\n",
      "Epoch:  24 | t:  100 | loss: 0.000 | input:  06-02-23<PAD><PAD><PAD> | target:  23/Feb/2006<EOS> | inference:  <GO>23/Feb/2006<EOS>\n",
      "Epoch:  25 | t:  0 | loss: 0.000 | input:  86-08-25<PAD><PAD><PAD> | target:  25/Aug/1986<EOS> | inference:  <GO>25/Aug/1986<EOS>\n",
      "Epoch:  25 | t:  50 | loss: 0.000 | input:  07-06-27<PAD><PAD><PAD> | target:  27/Jun/2007<EOS> | inference:  <GO>27/Jun/2007<EOS>\n",
      "Epoch:  25 | t:  100 | loss: 0.000 | input:  31-05-26<PAD><PAD><PAD> | target:  26/May/2031<EOS> | inference:  <GO>26/May/2031<EOS>\n",
      "Epoch:  26 | t:  0 | loss: 0.000 | input:  01-05-05<PAD><PAD><PAD> | target:  05/May/2001<EOS> | inference:  <GO>05/May/2001<EOS>\n",
      "Epoch:  26 | t:  50 | loss: 0.000 | input:  22-02-28<PAD><PAD><PAD> | target:  28/Feb/2022<EOS> | inference:  <GO>28/Feb/2022<EOS>\n",
      "Epoch:  26 | t:  100 | loss: 0.000 | input:  11-06-05<PAD><PAD><PAD> | target:  05/Jun/2011<EOS> | inference:  <GO>05/Jun/2011<EOS>\n",
      "Epoch:  27 | t:  0 | loss: 0.000 | input:  14-11-01<PAD><PAD><PAD> | target:  01/Nov/2014<EOS> | inference:  <GO>01/Nov/2014<EOS>\n",
      "Epoch:  27 | t:  50 | loss: 0.000 | input:  80-10-17<PAD><PAD><PAD> | target:  17/Oct/1980<EOS> | inference:  <GO>17/Oct/1980<EOS>\n",
      "Epoch:  27 | t:  100 | loss: 0.000 | input:  31-01-13<PAD><PAD><PAD> | target:  13/Jan/2031<EOS> | inference:  <GO>13/Jan/2031<EOS>\n",
      "Epoch:  28 | t:  0 | loss: 0.000 | input:  79-07-03<PAD><PAD><PAD> | target:  03/Jul/1979<EOS> | inference:  <GO>03/Jul/1979<EOS>\n",
      "Epoch:  28 | t:  50 | loss: 0.000 | input:  02-03-28<PAD><PAD><PAD> | target:  28/Mar/2002<EOS> | inference:  <GO>28/Mar/2002<EOS>\n",
      "Epoch:  28 | t:  100 | loss: 0.000 | input:  31-04-11<PAD><PAD><PAD> | target:  11/Apr/2031<EOS> | inference:  <GO>11/Apr/2031<EOS>\n",
      "Epoch:  29 | t:  0 | loss: 0.000 | input:  23-04-30<PAD><PAD><PAD> | target:  30/Apr/2023<EOS> | inference:  <GO>30/Apr/2023<EOS>\n",
      "Epoch:  29 | t:  50 | loss: 0.000 | input:  94-12-01<PAD><PAD><PAD> | target:  01/Dec/1994<EOS> | inference:  <GO>01/Dec/1994<EOS>\n",
      "Epoch:  29 | t:  100 | loss: 0.000 | input:  15-06-23<PAD><PAD><PAD> | target:  23/Jun/2015<EOS> | inference:  <GO>23/Jun/2015<EOS>\n",
      "Epoch:  30 | t:  0 | loss: 0.000 | input:  33-08-12<PAD><PAD><PAD> | target:  12/Aug/2033<EOS> | inference:  <GO>12/Aug/2033<EOS>\n",
      "Epoch:  30 | t:  50 | loss: 0.000 | input:  81-08-31<PAD><PAD><PAD> | target:  31/Aug/1981<EOS> | inference:  <GO>31/Aug/1981<EOS>\n",
      "Epoch:  30 | t:  100 | loss: 0.000 | input:  82-08-21<PAD><PAD><PAD> | target:  21/Aug/1982<EOS> | inference:  <GO>21/Aug/1982<EOS>\n",
      "Epoch:  31 | t:  0 | loss: 0.000 | input:  09-01-16<PAD><PAD><PAD> | target:  16/Jan/2009<EOS> | inference:  <GO>16/Jan/2009<EOS>\n",
      "Epoch:  31 | t:  50 | loss: 0.000 | input:  05-09-15<PAD><PAD><PAD> | target:  15/Sep/2005<EOS> | inference:  <GO>15/Sep/2005<EOS>\n",
      "Epoch:  31 | t:  100 | loss: 0.000 | input:  22-11-25<PAD><PAD><PAD> | target:  25/Nov/2022<EOS> | inference:  <GO>25/Nov/2022<EOS>\n",
      "Epoch:  32 | t:  0 | loss: 0.000 | input:  01-05-30<PAD><PAD><PAD> | target:  30/May/2001<EOS> | inference:  <GO>30/May/2001<EOS>\n",
      "Epoch:  32 | t:  50 | loss: 0.000 | input:  94-05-07<PAD><PAD><PAD> | target:  07/May/1994<EOS> | inference:  <GO>07/May/1994<EOS>\n",
      "Epoch:  32 | t:  100 | loss: 0.000 | input:  78-06-08<PAD><PAD><PAD> | target:  08/Jun/1978<EOS> | inference:  <GO>08/Jun/1978<EOS>\n",
      "Epoch:  33 | t:  0 | loss: 0.000 | input:  32-08-19<PAD><PAD><PAD> | target:  19/Aug/2032<EOS> | inference:  <GO>19/Aug/2032<EOS>\n",
      "Epoch:  33 | t:  50 | loss: 0.000 | input:  19-04-01<PAD><PAD><PAD> | target:  01/Apr/2019<EOS> | inference:  <GO>01/Apr/2019<EOS>\n",
      "Epoch:  33 | t:  100 | loss: 0.000 | input:  00-09-06<PAD><PAD><PAD> | target:  06/Sep/2000<EOS> | inference:  <GO>06/Sep/2000<EOS>\n",
      "Epoch:  34 | t:  0 | loss: 0.000 | input:  96-06-26<PAD><PAD><PAD> | target:  26/Jun/1996<EOS> | inference:  <GO>26/Jun/1996<EOS>\n",
      "Epoch:  34 | t:  50 | loss: 0.000 | input:  82-05-28<PAD><PAD><PAD> | target:  28/May/1982<EOS> | inference:  <GO>28/May/1982<EOS>\n",
      "Epoch:  34 | t:  100 | loss: 0.000 | input:  90-10-19<PAD><PAD><PAD> | target:  19/Oct/1990<EOS> | inference:  <GO>19/Oct/1990<EOS>\n",
      "Epoch:  35 | t:  0 | loss: 0.000 | input:  08-03-01<PAD><PAD><PAD> | target:  01/Mar/2008<EOS> | inference:  <GO>01/Mar/2008<EOS>\n",
      "Epoch:  35 | t:  50 | loss: 0.000 | input:  22-04-26<PAD><PAD><PAD> | target:  26/Apr/2022<EOS> | inference:  <GO>26/Apr/2022<EOS>\n",
      "Epoch:  35 | t:  100 | loss: 0.000 | input:  85-06-20<PAD><PAD><PAD> | target:  20/Jun/1985<EOS> | inference:  <GO>20/Jun/1985<EOS>\n",
      "Epoch:  36 | t:  0 | loss: 0.000 | input:  14-10-15<PAD><PAD><PAD> | target:  15/Oct/2014<EOS> | inference:  <GO>15/Oct/2014<EOS>\n",
      "Epoch:  36 | t:  50 | loss: 0.000 | input:  98-08-02<PAD><PAD><PAD> | target:  02/Aug/1998<EOS> | inference:  <GO>02/Aug/1998<EOS>\n",
      "Epoch:  36 | t:  100 | loss: 0.000 | input:  07-09-07<PAD><PAD><PAD> | target:  07/Sep/2007<EOS> | inference:  <GO>07/Sep/2007<EOS>\n",
      "Epoch:  37 | t:  0 | loss: 0.000 | input:  10-03-20<PAD><PAD><PAD> | target:  20/Mar/2010<EOS> | inference:  <GO>20/Mar/2010<EOS>\n",
      "Epoch:  37 | t:  50 | loss: 0.000 | input:  78-10-11<PAD><PAD><PAD> | target:  11/Oct/1978<EOS> | inference:  <GO>11/Oct/1978<EOS>\n",
      "Epoch:  37 | t:  100 | loss: 0.000 | input:  77-01-20<PAD><PAD><PAD> | target:  20/Jan/1977<EOS> | inference:  <GO>20/Jan/1977<EOS>\n",
      "Epoch:  38 | t:  0 | loss: 0.000 | input:  87-09-24<PAD><PAD><PAD> | target:  24/Sep/1987<EOS> | inference:  <GO>24/Sep/1987<EOS>\n",
      "Epoch:  38 | t:  50 | loss: 0.000 | input:  96-06-19<PAD><PAD><PAD> | target:  19/Jun/1996<EOS> | inference:  <GO>19/Jun/1996<EOS>\n",
      "Epoch:  38 | t:  100 | loss: 0.000 | input:  01-06-25<PAD><PAD><PAD> | target:  25/Jun/2001<EOS> | inference:  <GO>25/Jun/2001<EOS>\n",
      "Epoch:  39 | t:  0 | loss: 0.000 | input:  03-10-31<PAD><PAD><PAD> | target:  31/Oct/2003<EOS> | inference:  <GO>31/Oct/2003<EOS>\n",
      "Epoch:  39 | t:  50 | loss: 0.000 | input:  04-03-24<PAD><PAD><PAD> | target:  24/Mar/2004<EOS> | inference:  <GO>24/Mar/2004<EOS>\n",
      "Epoch:  39 | t:  100 | loss: 0.000 | input:  22-03-10<PAD><PAD><PAD> | target:  10/Mar/2022<EOS> | inference:  <GO>10/Mar/2022<EOS>\n",
      "Epoch:  40 | t:  0 | loss: 0.000 | input:  32-02-18<PAD><PAD><PAD> | target:  18/Feb/2032<EOS> | inference:  <GO>18/Feb/2032<EOS>\n",
      "Epoch:  40 | t:  50 | loss: 0.000 | input:  23-08-03<PAD><PAD><PAD> | target:  03/Aug/2023<EOS> | inference:  <GO>03/Aug/2023<EOS>\n",
      "Epoch:  40 | t:  100 | loss: 0.000 | input:  33-08-12<PAD><PAD><PAD> | target:  12/Aug/2033<EOS> | inference:  <GO>12/Aug/2033<EOS>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  41 | t:  0 | loss: 0.000 | input:  79-08-31<PAD><PAD><PAD> | target:  31/Aug/1979<EOS> | inference:  <GO>31/Aug/1979<EOS>\n",
      "Epoch:  41 | t:  50 | loss: 0.000 | input:  07-08-13<PAD><PAD><PAD> | target:  13/Aug/2007<EOS> | inference:  <GO>13/Aug/2007<EOS>\n",
      "Epoch:  41 | t:  100 | loss: 0.000 | input:  01-11-16<PAD><PAD><PAD> | target:  16/Nov/2001<EOS> | inference:  <GO>16/Nov/2001<EOS>\n",
      "Epoch:  42 | t:  0 | loss: 0.000 | input:  04-04-12<PAD><PAD><PAD> | target:  12/Apr/2004<EOS> | inference:  <GO>12/Apr/2004<EOS>\n",
      "Epoch:  42 | t:  50 | loss: 0.000 | input:  32-05-04<PAD><PAD><PAD> | target:  04/May/2032<EOS> | inference:  <GO>04/May/2032<EOS>\n",
      "Epoch:  42 | t:  100 | loss: 0.000 | input:  97-08-03<PAD><PAD><PAD> | target:  03/Aug/1997<EOS> | inference:  <GO>03/Aug/1997<EOS>\n",
      "Epoch:  43 | t:  0 | loss: 0.000 | input:  87-02-15<PAD><PAD><PAD> | target:  15/Feb/1987<EOS> | inference:  <GO>15/Feb/1987<EOS>\n",
      "Epoch:  43 | t:  50 | loss: 0.000 | input:  83-11-01<PAD><PAD><PAD> | target:  01/Nov/1983<EOS> | inference:  <GO>01/Nov/1983<EOS>\n",
      "Epoch:  43 | t:  100 | loss: 0.000 | input:  30-12-04<PAD><PAD><PAD> | target:  04/Dec/2030<EOS> | inference:  <GO>04/Dec/2030<EOS>\n",
      "Epoch:  44 | t:  0 | loss: 0.000 | input:  32-11-22<PAD><PAD><PAD> | target:  22/Nov/2032<EOS> | inference:  <GO>22/Nov/2032<EOS>\n",
      "Epoch:  44 | t:  50 | loss: 0.000 | input:  30-03-02<PAD><PAD><PAD> | target:  02/Mar/2030<EOS> | inference:  <GO>02/Mar/2030<EOS>\n",
      "Epoch:  44 | t:  100 | loss: 0.000 | input:  91-05-21<PAD><PAD><PAD> | target:  21/May/1991<EOS> | inference:  <GO>21/May/1991<EOS>\n",
      "Epoch:  45 | t:  0 | loss: 0.000 | input:  93-07-07<PAD><PAD><PAD> | target:  07/Jul/1993<EOS> | inference:  <GO>07/Jul/1993<EOS>\n",
      "Epoch:  45 | t:  50 | loss: 0.000 | input:  94-02-07<PAD><PAD><PAD> | target:  07/Feb/1994<EOS> | inference:  <GO>07/Feb/1994<EOS>\n",
      "Epoch:  45 | t:  100 | loss: 0.000 | input:  03-01-08<PAD><PAD><PAD> | target:  08/Jan/2003<EOS> | inference:  <GO>08/Jan/2003<EOS>\n",
      "Epoch:  46 | t:  0 | loss: 0.000 | input:  07-04-02<PAD><PAD><PAD> | target:  02/Apr/2007<EOS> | inference:  <GO>02/Apr/2007<EOS>\n",
      "Epoch:  46 | t:  50 | loss: 0.000 | input:  91-10-21<PAD><PAD><PAD> | target:  21/Oct/1991<EOS> | inference:  <GO>21/Oct/1991<EOS>\n",
      "Epoch:  46 | t:  100 | loss: 0.000 | input:  22-03-02<PAD><PAD><PAD> | target:  02/Mar/2022<EOS> | inference:  <GO>02/Mar/2022<EOS>\n",
      "Epoch:  47 | t:  0 | loss: 0.000 | input:  10-06-21<PAD><PAD><PAD> | target:  21/Jun/2010<EOS> | inference:  <GO>21/Jun/2010<EOS>\n",
      "Epoch:  47 | t:  50 | loss: 0.000 | input:  84-05-08<PAD><PAD><PAD> | target:  08/May/1984<EOS> | inference:  <GO>08/May/1984<EOS>\n",
      "Epoch:  47 | t:  100 | loss: 0.000 | input:  89-07-15<PAD><PAD><PAD> | target:  15/Jul/1989<EOS> | inference:  <GO>15/Jul/1989<EOS>\n",
      "Epoch:  48 | t:  0 | loss: 0.000 | input:  89-12-14<PAD><PAD><PAD> | target:  14/Dec/1989<EOS> | inference:  <GO>14/Dec/1989<EOS>\n",
      "Epoch:  48 | t:  50 | loss: 0.000 | input:  01-09-25<PAD><PAD><PAD> | target:  25/Sep/2001<EOS> | inference:  <GO>25/Sep/2001<EOS>\n",
      "Epoch:  48 | t:  100 | loss: 0.000 | input:  23-06-05<PAD><PAD><PAD> | target:  05/Jun/2023<EOS> | inference:  <GO>05/Jun/2023<EOS>\n",
      "Epoch:  49 | t:  0 | loss: 0.000 | input:  26-10-15<PAD><PAD><PAD> | target:  15/Oct/2026<EOS> | inference:  <GO>15/Oct/2026<EOS>\n",
      "Epoch:  49 | t:  50 | loss: 0.000 | input:  30-10-01<PAD><PAD><PAD> | target:  01/Oct/2030<EOS> | inference:  <GO>01/Oct/2030<EOS>\n",
      "Epoch:  49 | t:  100 | loss: 0.000 | input:  90-10-22<PAD><PAD><PAD> | target:  22/Oct/1990<EOS> | inference:  <GO>22/Oct/1990<EOS>\n",
      "Epoch:  50 | t:  0 | loss: 0.000 | input:  28-02-17<PAD><PAD><PAD> | target:  17/Feb/2028<EOS> | inference:  <GO>17/Feb/2028<EOS>\n",
      "Epoch:  50 | t:  50 | loss: 0.000 | input:  81-01-14<PAD><PAD><PAD> | target:  14/Jan/1981<EOS> | inference:  <GO>14/Jan/1981<EOS>\n",
      "Epoch:  50 | t:  100 | loss: 0.000 | input:  09-01-16<PAD><PAD><PAD> | target:  16/Jan/2009<EOS> | inference:  <GO>16/Jan/2009<EOS>\n",
      "Epoch:  51 | t:  0 | loss: 0.000 | input:  01-07-09<PAD><PAD><PAD> | target:  09/Jul/2001<EOS> | inference:  <GO>09/Jul/2001<EOS>\n",
      "Epoch:  51 | t:  50 | loss: 0.000 | input:  89-01-05<PAD><PAD><PAD> | target:  05/Jan/1989<EOS> | inference:  <GO>05/Jan/1989<EOS>\n",
      "Epoch:  51 | t:  100 | loss: 0.000 | input:  19-05-10<PAD><PAD><PAD> | target:  10/May/2019<EOS> | inference:  <GO>10/May/2019<EOS>\n",
      "Epoch:  52 | t:  0 | loss: 0.000 | input:  33-06-01<PAD><PAD><PAD> | target:  01/Jun/2033<EOS> | inference:  <GO>01/Jun/2033<EOS>\n",
      "Epoch:  52 | t:  50 | loss: 0.000 | input:  32-10-27<PAD><PAD><PAD> | target:  27/Oct/2032<EOS> | inference:  <GO>27/Oct/2032<EOS>\n",
      "Epoch:  52 | t:  100 | loss: 0.000 | input:  17-02-03<PAD><PAD><PAD> | target:  03/Feb/2017<EOS> | inference:  <GO>03/Feb/2017<EOS>\n",
      "Epoch:  53 | t:  0 | loss: 0.000 | input:  23-06-30<PAD><PAD><PAD> | target:  30/Jun/2023<EOS> | inference:  <GO>30/Jun/2023<EOS>\n",
      "Epoch:  53 | t:  50 | loss: 0.000 | input:  97-07-31<PAD><PAD><PAD> | target:  31/Jul/1997<EOS> | inference:  <GO>31/Jul/1997<EOS>\n",
      "Epoch:  53 | t:  100 | loss: 0.000 | input:  23-07-22<PAD><PAD><PAD> | target:  22/Jul/2023<EOS> | inference:  <GO>22/Jul/2023<EOS>\n",
      "Epoch:  54 | t:  0 | loss: 0.000 | input:  91-07-31<PAD><PAD><PAD> | target:  31/Jul/1991<EOS> | inference:  <GO>31/Jul/1991<EOS>\n",
      "Epoch:  54 | t:  50 | loss: 0.000 | input:  22-09-25<PAD><PAD><PAD> | target:  25/Sep/2022<EOS> | inference:  <GO>25/Sep/2022<EOS>\n",
      "Epoch:  54 | t:  100 | loss: 0.000 | input:  10-06-21<PAD><PAD><PAD> | target:  21/Jun/2010<EOS> | inference:  <GO>21/Jun/2010<EOS>\n",
      "Epoch:  55 | t:  0 | loss: 0.000 | input:  11-04-05<PAD><PAD><PAD> | target:  05/Apr/2011<EOS> | inference:  <GO>05/Apr/2011<EOS>\n",
      "Epoch:  55 | t:  50 | loss: 0.000 | input:  90-11-06<PAD><PAD><PAD> | target:  06/Nov/1990<EOS> | inference:  <GO>06/Nov/1990<EOS>\n",
      "Epoch:  55 | t:  100 | loss: 0.000 | input:  05-09-02<PAD><PAD><PAD> | target:  02/Sep/2005<EOS> | inference:  <GO>02/Sep/2005<EOS>\n",
      "Epoch:  56 | t:  0 | loss: 0.000 | input:  76-04-15<PAD><PAD><PAD> | target:  15/Apr/1976<EOS> | inference:  <GO>15/Apr/1976<EOS>\n",
      "Epoch:  56 | t:  50 | loss: 0.000 | input:  95-02-22<PAD><PAD><PAD> | target:  22/Feb/1995<EOS> | inference:  <GO>22/Feb/1995<EOS>\n",
      "Epoch:  56 | t:  100 | loss: 0.000 | input:  23-01-24<PAD><PAD><PAD> | target:  24/Jan/2023<EOS> | inference:  <GO>24/Jan/2023<EOS>\n",
      "Epoch:  57 | t:  0 | loss: 0.000 | input:  16-02-06<PAD><PAD><PAD> | target:  06/Feb/2016<EOS> | inference:  <GO>06/Feb/2016<EOS>\n",
      "Epoch:  57 | t:  50 | loss: 0.000 | input:  74-11-27<PAD><PAD><PAD> | target:  27/Nov/1974<EOS> | inference:  <GO>27/Nov/1974<EOS>\n",
      "Epoch:  57 | t:  100 | loss: 0.000 | input:  05-06-29<PAD><PAD><PAD> | target:  29/Jun/2005<EOS> | inference:  <GO>29/Jun/2005<EOS>\n",
      "Epoch:  58 | t:  0 | loss: 0.000 | input:  79-08-04<PAD><PAD><PAD> | target:  04/Aug/1979<EOS> | inference:  <GO>04/Aug/1979<EOS>\n",
      "Epoch:  58 | t:  50 | loss: 0.000 | input:  04-05-07<PAD><PAD><PAD> | target:  07/May/2004<EOS> | inference:  <GO>07/May/2004<EOS>\n",
      "Epoch:  58 | t:  100 | loss: 0.000 | input:  75-07-12<PAD><PAD><PAD> | target:  12/Jul/1975<EOS> | inference:  <GO>12/Jul/1975<EOS>\n",
      "Epoch:  59 | t:  0 | loss: 0.000 | input:  21-06-03<PAD><PAD><PAD> | target:  03/Jun/2021<EOS> | inference:  <GO>03/Jun/2021<EOS>\n",
      "Epoch:  59 | t:  50 | loss: 0.000 | input:  98-11-01<PAD><PAD><PAD> | target:  01/Nov/1998<EOS> | inference:  <GO>01/Nov/1998<EOS>\n",
      "Epoch:  59 | t:  100 | loss: 0.000 | input:  05-08-31<PAD><PAD><PAD> | target:  31/Aug/2005<EOS> | inference:  <GO>31/Aug/2005<EOS>\n",
      "Epoch:  60 | t:  0 | loss: 0.000 | input:  12-12-13<PAD><PAD><PAD> | target:  13/Dec/2012<EOS> | inference:  <GO>13/Dec/2012<EOS>\n",
      "Epoch:  60 | t:  50 | loss: 0.000 | input:  16-09-05<PAD><PAD><PAD> | target:  05/Sep/2016<EOS> | inference:  <GO>05/Sep/2016<EOS>\n",
      "Epoch:  60 | t:  100 | loss: 0.000 | input:  19-10-11<PAD><PAD><PAD> | target:  11/Oct/2019<EOS> | inference:  <GO>11/Oct/2019<EOS>\n",
      "Epoch:  61 | t:  0 | loss: 0.000 | input:  27-10-21<PAD><PAD><PAD> | target:  21/Oct/2027<EOS> | inference:  <GO>21/Oct/2027<EOS>\n",
      "Epoch:  61 | t:  50 | loss: 0.000 | input:  26-06-13<PAD><PAD><PAD> | target:  13/Jun/2026<EOS> | inference:  <GO>13/Jun/2026<EOS>\n",
      "Epoch:  61 | t:  100 | loss: 0.000 | input:  06-09-09<PAD><PAD><PAD> | target:  09/Sep/2006<EOS> | inference:  <GO>09/Sep/2006<EOS>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  62 | t:  0 | loss: 0.000 | input:  31-04-27<PAD><PAD><PAD> | target:  27/Apr/2031<EOS> | inference:  <GO>27/Apr/2031<EOS>\n",
      "Epoch:  62 | t:  50 | loss: 0.000 | input:  79-09-17<PAD><PAD><PAD> | target:  17/Sep/1979<EOS> | inference:  <GO>17/Sep/1979<EOS>\n",
      "Epoch:  62 | t:  100 | loss: 0.000 | input:  16-06-12<PAD><PAD><PAD> | target:  12/Jun/2016<EOS> | inference:  <GO>12/Jun/2016<EOS>\n",
      "Epoch:  63 | t:  0 | loss: 0.000 | input:  21-05-11<PAD><PAD><PAD> | target:  11/May/2021<EOS> | inference:  <GO>11/May/2021<EOS>\n",
      "Epoch:  63 | t:  50 | loss: 0.000 | input:  92-03-27<PAD><PAD><PAD> | target:  27/Mar/1992<EOS> | inference:  <GO>27/Mar/1992<EOS>\n",
      "Epoch:  63 | t:  100 | loss: 0.000 | input:  29-04-13<PAD><PAD><PAD> | target:  13/Apr/2029<EOS> | inference:  <GO>13/Apr/2029<EOS>\n",
      "Epoch:  64 | t:  0 | loss: 0.000 | input:  28-03-28<PAD><PAD><PAD> | target:  28/Mar/2028<EOS> | inference:  <GO>28/Mar/2028<EOS>\n",
      "Epoch:  64 | t:  50 | loss: 0.000 | input:  01-09-10<PAD><PAD><PAD> | target:  10/Sep/2001<EOS> | inference:  <GO>10/Sep/2001<EOS>\n",
      "Epoch:  64 | t:  100 | loss: 0.000 | input:  31-05-09<PAD><PAD><PAD> | target:  09/May/2031<EOS> | inference:  <GO>09/May/2031<EOS>\n",
      "Epoch:  65 | t:  0 | loss: 0.000 | input:  05-03-26<PAD><PAD><PAD> | target:  26/Mar/2005<EOS> | inference:  <GO>26/Mar/2005<EOS>\n",
      "Epoch:  65 | t:  50 | loss: 0.000 | input:  13-02-19<PAD><PAD><PAD> | target:  19/Feb/2013<EOS> | inference:  <GO>19/Feb/2013<EOS>\n",
      "Epoch:  65 | t:  100 | loss: 0.000 | input:  93-08-12<PAD><PAD><PAD> | target:  12/Aug/1993<EOS> | inference:  <GO>12/Aug/1993<EOS>\n",
      "Epoch:  66 | t:  0 | loss: 0.000 | input:  80-02-24<PAD><PAD><PAD> | target:  24/Feb/1980<EOS> | inference:  <GO>24/Feb/1980<EOS>\n",
      "Epoch:  66 | t:  50 | loss: 0.000 | input:  28-07-20<PAD><PAD><PAD> | target:  20/Jul/2028<EOS> | inference:  <GO>20/Jul/2028<EOS>\n",
      "Epoch:  66 | t:  100 | loss: 0.000 | input:  92-05-06<PAD><PAD><PAD> | target:  06/May/1992<EOS> | inference:  <GO>06/May/1992<EOS>\n",
      "Epoch:  67 | t:  0 | loss: 0.000 | input:  78-07-10<PAD><PAD><PAD> | target:  10/Jul/1978<EOS> | inference:  <GO>10/Jul/1978<EOS>\n",
      "Epoch:  67 | t:  50 | loss: 0.000 | input:  83-09-11<PAD><PAD><PAD> | target:  11/Sep/1983<EOS> | inference:  <GO>11/Sep/1983<EOS>\n",
      "Epoch:  67 | t:  100 | loss: 0.000 | input:  32-05-09<PAD><PAD><PAD> | target:  09/May/2032<EOS> | inference:  <GO>09/May/2032<EOS>\n",
      "Epoch:  68 | t:  0 | loss: 0.000 | input:  78-05-04<PAD><PAD><PAD> | target:  04/May/1978<EOS> | inference:  <GO>04/May/1978<EOS>\n",
      "Epoch:  68 | t:  50 | loss: 0.000 | input:  32-01-03<PAD><PAD><PAD> | target:  03/Jan/2032<EOS> | inference:  <GO>03/Jan/2032<EOS>\n",
      "Epoch:  68 | t:  100 | loss: 0.000 | input:  89-09-07<PAD><PAD><PAD> | target:  07/Sep/1989<EOS> | inference:  <GO>07/Sep/1989<EOS>\n",
      "Epoch:  69 | t:  0 | loss: 0.000 | input:  31-11-13<PAD><PAD><PAD> | target:  13/Nov/2031<EOS> | inference:  <GO>13/Nov/2031<EOS>\n",
      "Epoch:  69 | t:  50 | loss: 0.000 | input:  09-02-09<PAD><PAD><PAD> | target:  09/Feb/2009<EOS> | inference:  <GO>09/Feb/2009<EOS>\n",
      "Epoch:  69 | t:  100 | loss: 0.000 | input:  03-06-03<PAD><PAD><PAD> | target:  03/Jun/2003<EOS> | inference:  <GO>03/Jun/2003<EOS>\n",
      "Epoch:  70 | t:  0 | loss: 0.000 | input:  32-10-27<PAD><PAD><PAD> | target:  27/Oct/2032<EOS> | inference:  <GO>27/Oct/2032<EOS>\n",
      "Epoch:  70 | t:  50 | loss: 0.000 | input:  99-11-02<PAD><PAD><PAD> | target:  02/Nov/1999<EOS> | inference:  <GO>02/Nov/1999<EOS>\n",
      "Epoch:  70 | t:  100 | loss: 0.000 | input:  29-05-25<PAD><PAD><PAD> | target:  25/May/2029<EOS> | inference:  <GO>25/May/2029<EOS>\n",
      "Epoch:  71 | t:  0 | loss: 0.000 | input:  81-02-17<PAD><PAD><PAD> | target:  17/Feb/1981<EOS> | inference:  <GO>17/Feb/1981<EOS>\n",
      "Epoch:  71 | t:  50 | loss: 0.000 | input:  84-08-29<PAD><PAD><PAD> | target:  29/Aug/1984<EOS> | inference:  <GO>29/Aug/1984<EOS>\n",
      "Epoch:  71 | t:  100 | loss: 0.000 | input:  08-02-16<PAD><PAD><PAD> | target:  16/Feb/2008<EOS> | inference:  <GO>16/Feb/2008<EOS>\n",
      "Epoch:  72 | t:  0 | loss: 0.000 | input:  22-06-25<PAD><PAD><PAD> | target:  25/Jun/2022<EOS> | inference:  <GO>25/Jun/2022<EOS>\n",
      "Epoch:  72 | t:  50 | loss: 0.000 | input:  24-01-28<PAD><PAD><PAD> | target:  28/Jan/2024<EOS> | inference:  <GO>28/Jan/2024<EOS>\n",
      "Epoch:  72 | t:  100 | loss: 0.000 | input:  06-06-15<PAD><PAD><PAD> | target:  15/Jun/2006<EOS> | inference:  <GO>15/Jun/2006<EOS>\n",
      "Epoch:  73 | t:  0 | loss: 0.000 | input:  96-11-06<PAD><PAD><PAD> | target:  06/Nov/1996<EOS> | inference:  <GO>06/Nov/1996<EOS>\n",
      "Epoch:  73 | t:  50 | loss: 0.000 | input:  19-04-11<PAD><PAD><PAD> | target:  11/Apr/2019<EOS> | inference:  <GO>11/Apr/2019<EOS>\n",
      "Epoch:  73 | t:  100 | loss: 0.000 | input:  32-07-03<PAD><PAD><PAD> | target:  03/Jul/2032<EOS> | inference:  <GO>03/Jul/2032<EOS>\n",
      "Epoch:  74 | t:  0 | loss: 0.000 | input:  91-03-22<PAD><PAD><PAD> | target:  22/Mar/1991<EOS> | inference:  <GO>22/Mar/1991<EOS>\n",
      "Epoch:  74 | t:  50 | loss: 0.000 | input:  01-01-12<PAD><PAD><PAD> | target:  12/Jan/2001<EOS> | inference:  <GO>12/Jan/2001<EOS>\n",
      "Epoch:  74 | t:  100 | loss: 0.000 | input:  29-10-15<PAD><PAD><PAD> | target:  15/Oct/2029<EOS> | inference:  <GO>15/Oct/2029<EOS>\n",
      "Epoch:  75 | t:  0 | loss: 0.000 | input:  75-09-17<PAD><PAD><PAD> | target:  17/Sep/1975<EOS> | inference:  <GO>17/Sep/1975<EOS>\n",
      "Epoch:  75 | t:  50 | loss: 0.000 | input:  21-11-14<PAD><PAD><PAD> | target:  14/Nov/2021<EOS> | inference:  <GO>14/Nov/2021<EOS>\n",
      "Epoch:  75 | t:  100 | loss: 0.000 | input:  81-06-27<PAD><PAD><PAD> | target:  27/Jun/1981<EOS> | inference:  <GO>27/Jun/1981<EOS>\n",
      "Epoch:  76 | t:  0 | loss: 1.070 | input:  10-01-28<PAD><PAD><PAD> | target:  28/Jan/2010<EOS> | inference:  <GO>28/Jan/199<EOS>\n",
      "Epoch:  76 | t:  50 | loss: 0.021 | input:  23-03-19<PAD><PAD><PAD> | target:  19/Mar/2023<EOS> | inference:  <GO>19/Mar/2023<EOS>\n",
      "Epoch:  76 | t:  100 | loss: 0.003 | input:  20-10-02<PAD><PAD><PAD> | target:  02/Oct/2020<EOS> | inference:  <GO>02/Oct/2020<EOS>\n",
      "Epoch:  77 | t:  0 | loss: 0.003 | input:  28-06-28<PAD><PAD><PAD> | target:  28/Jun/2028<EOS> | inference:  <GO>28/Jun/2028<EOS>\n",
      "Epoch:  77 | t:  50 | loss: 0.002 | input:  81-01-14<PAD><PAD><PAD> | target:  14/Jan/1981<EOS> | inference:  <GO>14/Jan/1981<EOS>\n",
      "Epoch:  77 | t:  100 | loss: 0.001 | input:  80-10-16<PAD><PAD><PAD> | target:  16/Oct/1980<EOS> | inference:  <GO>16/Oct/1980<EOS>\n",
      "Epoch:  78 | t:  0 | loss: 0.001 | input:  30-11-18<PAD><PAD><PAD> | target:  18/Nov/2030<EOS> | inference:  <GO>18/Nov/2030<EOS>\n",
      "Epoch:  78 | t:  50 | loss: 0.001 | input:  30-06-20<PAD><PAD><PAD> | target:  20/Jun/2030<EOS> | inference:  <GO>20/Jun/2030<EOS>\n",
      "Epoch:  78 | t:  100 | loss: 0.001 | input:  86-11-11<PAD><PAD><PAD> | target:  11/Nov/1986<EOS> | inference:  <GO>11/Nov/1986<EOS>\n",
      "Epoch:  79 | t:  0 | loss: 0.001 | input:  98-10-17<PAD><PAD><PAD> | target:  17/Oct/1998<EOS> | inference:  <GO>17/Oct/1998<EOS>\n",
      "Epoch:  79 | t:  50 | loss: 0.001 | input:  27-09-03<PAD><PAD><PAD> | target:  03/Sep/2027<EOS> | inference:  <GO>03/Sep/2027<EOS>\n",
      "Epoch:  79 | t:  100 | loss: 0.001 | input:  00-03-26<PAD><PAD><PAD> | target:  26/Mar/2000<EOS> | inference:  <GO>26/Mar/2000<EOS>\n",
      "Epoch:  80 | t:  0 | loss: 0.001 | input:  31-02-08<PAD><PAD><PAD> | target:  08/Feb/2031<EOS> | inference:  <GO>08/Feb/2031<EOS>\n",
      "Epoch:  80 | t:  50 | loss: 0.001 | input:  75-10-03<PAD><PAD><PAD> | target:  03/Oct/1975<EOS> | inference:  <GO>03/Oct/1975<EOS>\n",
      "Epoch:  80 | t:  100 | loss: 0.000 | input:  83-09-29<PAD><PAD><PAD> | target:  29/Sep/1983<EOS> | inference:  <GO>29/Sep/1983<EOS>\n",
      "Epoch:  81 | t:  0 | loss: 0.001 | input:  90-12-11<PAD><PAD><PAD> | target:  11/Dec/1990<EOS> | inference:  <GO>11/Dec/1990<EOS>\n",
      "Epoch:  81 | t:  50 | loss: 0.001 | input:  75-04-02<PAD><PAD><PAD> | target:  02/Apr/1975<EOS> | inference:  <GO>02/Apr/1975<EOS>\n",
      "Epoch:  81 | t:  100 | loss: 0.000 | input:  19-09-14<PAD><PAD><PAD> | target:  14/Sep/2019<EOS> | inference:  <GO>14/Sep/2019<EOS>\n",
      "Epoch:  82 | t:  0 | loss: 0.000 | input:  19-06-30<PAD><PAD><PAD> | target:  30/Jun/2019<EOS> | inference:  <GO>30/Jun/2019<EOS>\n",
      "Epoch:  82 | t:  50 | loss: 0.000 | input:  79-03-31<PAD><PAD><PAD> | target:  31/Mar/1979<EOS> | inference:  <GO>31/Mar/1979<EOS>\n",
      "Epoch:  82 | t:  100 | loss: 0.000 | input:  01-03-27<PAD><PAD><PAD> | target:  27/Mar/2001<EOS> | inference:  <GO>27/Mar/2001<EOS>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  83 | t:  0 | loss: 0.000 | input:  26-08-12<PAD><PAD><PAD> | target:  12/Aug/2026<EOS> | inference:  <GO>12/Aug/2026<EOS>\n",
      "Epoch:  83 | t:  50 | loss: 0.000 | input:  14-03-10<PAD><PAD><PAD> | target:  10/Mar/2014<EOS> | inference:  <GO>10/Mar/2014<EOS>\n",
      "Epoch:  83 | t:  100 | loss: 0.000 | input:  76-08-01<PAD><PAD><PAD> | target:  01/Aug/1976<EOS> | inference:  <GO>01/Aug/1976<EOS>\n",
      "Epoch:  84 | t:  0 | loss: 0.000 | input:  79-07-06<PAD><PAD><PAD> | target:  06/Jul/1979<EOS> | inference:  <GO>06/Jul/1979<EOS>\n",
      "Epoch:  84 | t:  50 | loss: 0.001 | input:  06-07-14<PAD><PAD><PAD> | target:  14/Jul/2006<EOS> | inference:  <GO>14/Jul/2006<EOS>\n",
      "Epoch:  84 | t:  100 | loss: 0.004 | input:  33-07-05<PAD><PAD><PAD> | target:  05/Jul/2033<EOS> | inference:  <GO>05/Jul/2033<EOS>\n",
      "Epoch:  85 | t:  0 | loss: 0.002 | input:  01-09-25<PAD><PAD><PAD> | target:  25/Sep/2001<EOS> | inference:  <GO>25/Sep/2001<EOS>\n",
      "Epoch:  85 | t:  50 | loss: 0.001 | input:  75-12-18<PAD><PAD><PAD> | target:  18/Dec/1975<EOS> | inference:  <GO>18/Dec/1975<EOS>\n",
      "Epoch:  85 | t:  100 | loss: 0.000 | input:  30-02-08<PAD><PAD><PAD> | target:  08/Feb/2030<EOS> | inference:  <GO>08/Feb/2030<EOS>\n",
      "Epoch:  86 | t:  0 | loss: 0.000 | input:  93-03-10<PAD><PAD><PAD> | target:  10/Mar/1993<EOS> | inference:  <GO>10/Mar/1993<EOS>\n",
      "Epoch:  86 | t:  50 | loss: 0.000 | input:  87-12-27<PAD><PAD><PAD> | target:  27/Dec/1987<EOS> | inference:  <GO>27/Dec/1987<EOS>\n",
      "Epoch:  86 | t:  100 | loss: 0.000 | input:  84-07-25<PAD><PAD><PAD> | target:  25/Jul/1984<EOS> | inference:  <GO>25/Jul/1984<EOS>\n",
      "Epoch:  87 | t:  0 | loss: 0.000 | input:  92-09-08<PAD><PAD><PAD> | target:  08/Sep/1992<EOS> | inference:  <GO>08/Sep/1992<EOS>\n",
      "Epoch:  87 | t:  50 | loss: 0.000 | input:  28-12-01<PAD><PAD><PAD> | target:  01/Dec/2028<EOS> | inference:  <GO>01/Dec/2028<EOS>\n",
      "Epoch:  87 | t:  100 | loss: 0.000 | input:  25-02-20<PAD><PAD><PAD> | target:  20/Feb/2025<EOS> | inference:  <GO>20/Feb/2025<EOS>\n",
      "Epoch:  88 | t:  0 | loss: 0.000 | input:  18-04-22<PAD><PAD><PAD> | target:  22/Apr/2018<EOS> | inference:  <GO>22/Apr/2018<EOS>\n",
      "Epoch:  88 | t:  50 | loss: 0.000 | input:  97-09-28<PAD><PAD><PAD> | target:  28/Sep/1997<EOS> | inference:  <GO>28/Sep/1997<EOS>\n",
      "Epoch:  88 | t:  100 | loss: 0.000 | input:  17-02-03<PAD><PAD><PAD> | target:  03/Feb/2017<EOS> | inference:  <GO>03/Feb/2017<EOS>\n",
      "Epoch:  89 | t:  0 | loss: 0.000 | input:  05-04-16<PAD><PAD><PAD> | target:  16/Apr/2005<EOS> | inference:  <GO>16/Apr/2005<EOS>\n",
      "Epoch:  89 | t:  50 | loss: 0.000 | input:  93-05-08<PAD><PAD><PAD> | target:  08/May/1993<EOS> | inference:  <GO>08/May/1993<EOS>\n",
      "Epoch:  89 | t:  100 | loss: 0.000 | input:  02-01-24<PAD><PAD><PAD> | target:  24/Jan/2002<EOS> | inference:  <GO>24/Jan/2002<EOS>\n",
      "Epoch:  90 | t:  0 | loss: 0.000 | input:  81-10-27<PAD><PAD><PAD> | target:  27/Oct/1981<EOS> | inference:  <GO>27/Oct/1981<EOS>\n",
      "Epoch:  90 | t:  50 | loss: 0.000 | input:  34-03-26<PAD><PAD><PAD> | target:  26/Mar/2034<EOS> | inference:  <GO>26/Mar/2034<EOS>\n",
      "Epoch:  90 | t:  100 | loss: 0.000 | input:  76-01-23<PAD><PAD><PAD> | target:  23/Jan/1976<EOS> | inference:  <GO>23/Jan/1976<EOS>\n",
      "Epoch:  91 | t:  0 | loss: 0.000 | input:  75-10-09<PAD><PAD><PAD> | target:  09/Oct/1975<EOS> | inference:  <GO>09/Oct/1975<EOS>\n",
      "Epoch:  91 | t:  50 | loss: 0.000 | input:  91-12-30<PAD><PAD><PAD> | target:  30/Dec/1991<EOS> | inference:  <GO>30/Dec/1991<EOS>\n",
      "Epoch:  91 | t:  100 | loss: 0.000 | input:  08-07-21<PAD><PAD><PAD> | target:  21/Jul/2008<EOS> | inference:  <GO>21/Jul/2008<EOS>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--emb_dim\",type=int, help=\"change the model dimension\")\n",
    "    parser.add_argument(\"--n_layer\",type=int, help=\"change the number of layers in Encoder and Decoder\")\n",
    "    parser.add_argument(\"--n_head\",type=int, help=\"change the number of heads in MultiHeadAttention\")\n",
    "\n",
    "    args = parser.parse_args(args=[])\n",
    "    args = dict(filter(lambda x: x[1],vars(args).items()))\n",
    "    train(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5d2811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:All]",
   "language": "python",
   "name": "conda-env-All-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
